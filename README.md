# DocuMind - POC AnÃ¡lisis de Documentos PDF con RAG

Una aplicaciÃ³n web desarrollada con Next.js 14+ que permite subir archivos PDF, visualizarlos, extraer palabras clave automÃ¡ticamente y chatear con los documentos usando RAG (Retrieval-Augmented Generation).

## ğŸš€ CaracterÃ­sticas

- **Subida de archivos PDF**: Interfaz drag & drop para cargar documentos
- **VisualizaciÃ³n de PDF**: Visor integrado con navegaciÃ³n entre pÃ¡ginas
- **ExtracciÃ³n de palabras clave**: AnÃ¡lisis automÃ¡tico usando OpenAI GPT
- **ğŸ’¡ RAG (Retrieval-Augmented Generation)**:
  - Chat interactivo con tus documentos PDF
  - BÃºsqueda semÃ¡ntica usando embeddings de OpenAI
  - Almacenamiento vectorial con Supabase + pgvector
  - Respuestas contextualizadas en tiempo real con streaming
- **Arquitectura limpia**: ImplementaciÃ³n con Clean Architecture/Hexagonal
- **UI moderna**: Interfaz oscura con Material UI
- **TypeScript**: Tipado estÃ¡tico completo

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Frontend**: Next.js 14+ (App Router), React 18, TypeScript
- **UI**: Material UI (MUI), CSS-in-JS
- **PDF**: react-pdf (pdfjs-dist)
- **Backend**: Next.js API Routes, pdf-parse
- **IA**: OpenAI Node SDK (GPT-4o, text-embedding-3-small)
- **RAG**:
  - **Vector Store**: Supabase con extensiÃ³n pgvector
  - **Embeddings**: OpenAI text-embedding-3-small (1536 dimensiones)
  - **Streaming**: Vercel AI SDK v5
  - **Chunking**: RecursiveTextChunker (configurable)
- **Arquitectura**: Clean Architecture / Hexagonal

## ğŸ“ Estructura del Proyecto

```
src/
â”œâ”€â”€ app/                          # Next.js App Router
â”‚   â”œâ”€â”€ analyze/                  # PÃ¡gina de anÃ¡lisis de PDFs
â”‚   â”‚   â”œâ”€â”€ page.tsx             # Componente principal
â”‚   â”‚   â””â”€â”€ components/          # Componentes UI
â”‚   â”œâ”€â”€ api/                     # API Routes
â”‚   â”‚   â”œâ”€â”€ analyze/             # AnÃ¡lisis de keywords
â”‚   â”‚   â”œâ”€â”€ chat/                # Chat RAG con documentos
â”‚   â”‚   â””â”€â”€ documents/store/     # Almacenamiento de documentos
â”‚   â”œâ”€â”€ layout.tsx               # Layout raÃ­z
â”‚   â””â”€â”€ globals.css              # Estilos globales
â”œâ”€â”€ components/                  # Componentes compartidos
â”‚   â”œâ”€â”€ chat/                    # Componentes del chat
â”‚   â”‚   â”œâ”€â”€ ChatWidget.tsx       # Widget de chat principal
â”‚   â”‚   â””â”€â”€ ChatMessage.tsx      # Mensaje individual
â”‚   â””â”€â”€ UploadDropzone.tsx       # Zona de carga de archivos
â”œâ”€â”€ core/                        # LÃ³gica de dominio (Clean Architecture)
â”‚   â”œâ”€â”€ domain/                  # Entidades y puertos (interfaces)
â”‚   â”‚   â”œâ”€â”€ chat/                # Dominio de chat y RAG
â”‚   â”‚   â””â”€â”€ documents/           # Dominio de documentos
â”‚   â””â”€â”€ application/             # Casos de uso y servicios
â”‚       â””â”€â”€ chat/
â”‚           â”œâ”€â”€ use-cases/       # Casos de uso principales
â”‚           â”‚   â”œâ”€â”€ ChatWithDocsUseCase.ts      # Chat con RAG
â”‚           â”‚   â””â”€â”€ StoreDocumentUseCase.ts     # Almacenar documentos
â”‚           â””â”€â”€ services/        # Servicios de aplicaciÃ³n
â”‚               â”œâ”€â”€ ChatPromptBuilder.ts        # Constructor de prompts
â”‚               â””â”€â”€ ContextAssembler.ts         # Ensamblador de contexto
â”œâ”€â”€ infrastructure/              # Adaptadores externos
â”‚   â”œâ”€â”€ pdf/                     # Extractor de texto PDF
â”‚   â”œâ”€â”€ llm/                     # Cliente OpenAI para chat
â”‚   â”œâ”€â”€ embeddings/              # GeneraciÃ³n de embeddings
â”‚   â”‚   â””â”€â”€ OpenAIEmbeddingGenerator.ts
â”‚   â”œâ”€â”€ chunking/                # DivisiÃ³n de documentos
â”‚   â”‚   â””â”€â”€ RecursiveTextChunker.ts
â”‚   â””â”€â”€ vector-store/            # Almacenamiento vectorial
â”‚       â””â”€â”€ SupabaseVectorStore.ts
â”œâ”€â”€ composition/                 # InyecciÃ³n de dependencias
â”‚   â”œâ”€â”€ container.ts             # Contenedor principal
â”‚   â””â”€â”€ rag-container.ts         # Contenedor RAG
â””â”€â”€ lib/                         # Utilidades
    â”œâ”€â”€ env.ts                   # Variables de entorno
    â””â”€â”€ supabase.ts              # Cliente Supabase
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Instalar dependencias

Con Yarn (recomendado y configurado en el proyecto):
```bash
yarn install
```

O con npm (alternativo):
```bash
npm install
```

### 2. Configurar Supabase

Necesitas crear un proyecto en Supabase y configurar la base de datos vectorial:

1. Ve a [Supabase](https://supabase.com) y crea un nuevo proyecto
2. En el SQL Editor, ejecuta el siguiente script para crear la tabla de documentos con soporte vectorial:

```sql
-- Habilitar la extensiÃ³n pgvector
create extension if not exists vector;

-- Crear tabla de documentos
create table documents (
  id uuid primary key default gen_random_uuid(),
  title text not null,
  content text not null,
  embedding vector(1536),
  chunk_index integer,
  parent_document_id uuid,
  metadata jsonb,
  created_at timestamp with time zone default now()
);

-- Crear Ã­ndice para bÃºsqueda vectorial eficiente
create index on documents using ivfflat (embedding vector_cosine_ops)
  with (lists = 100);

-- Crear funciÃ³n para bÃºsqueda de similitud
create or replace function match_documents(
  query_embedding vector(1536),
  match_threshold float,
  match_count int,
  filter_parent_id uuid default null
)
returns table (
  id uuid,
  title text,
  content text,
  chunk_index integer,
  parent_document_id uuid,
  metadata jsonb,
  similarity float
)
language plpgsql
as $$
begin
  return query
  select
    documents.id,
    documents.title,
    documents.content,
    documents.chunk_index,
    documents.parent_document_id,
    documents.metadata,
    1 - (documents.embedding <=> query_embedding) as similarity
  from documents
  where
    (filter_parent_id is null or documents.parent_document_id = filter_parent_id)
    and 1 - (documents.embedding <=> query_embedding) > match_threshold
  order by documents.embedding <=> query_embedding
  limit match_count;
end;
$$;
```

### 3. Configurar variables de entorno

Copia el archivo de ejemplo y configÃºralo con tus credenciales:

```bash
cp .env.example .env.local
```

Luego edita `.env.local` con tus credenciales reales:

```env
# OpenAI API
OPENAI_API_KEY=sk-tu-api-key-aqui
OPENAI_MODEL=gpt-4o-mini

# Supabase
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_ANON_KEY=tu-anon-key-aqui

# ConfiguraciÃ³n de carga
MAX_UPLOAD_MB=20

# ConfiguraciÃ³n RAG (opcional, valores por defecto)
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
RAG_CHUNK_SIZE=1000
RAG_CHUNK_OVERLAP=200
RAG_MAX_RESULTS=5
RAG_SIMILARITY_THRESHOLD=0.7

# ConfiguraciÃ³n de Chat (opcional, valores por defecto)
CHAT_MODEL=gpt-4o
CHAT_MAX_TOKENS=2000
CHAT_TEMPERATURE=0.7
```

### 4. Ejecutar en desarrollo

Con Yarn:
```bash
yarn dev
```

O con npm:
```bash
npm run dev
```

### 5. Abrir la aplicaciÃ³n

Navega a [http://localhost:3000/analyze](http://localhost:3000/analyze)

## ğŸ“– Uso

### AnÃ¡lisis de Documentos (Keywords)

1. **Subir PDF**: Arrastra un archivo PDF o usa el botÃ³n "Seleccionar archivo"
2. **Visualizar**: El PDF se mostrarÃ¡ inmediatamente en la columna izquierda
3. **Analizar**: La aplicaciÃ³n extraerÃ¡ automÃ¡ticamente el texto y generarÃ¡ palabras clave
4. **Revisar**: Las palabras clave aparecerÃ¡n como chips de colores en la columna derecha

### Chat con Documentos (RAG)

1. **Subir documento**: Carga un PDF que serÃ¡ procesado y almacenado en la base de datos vectorial
   - El documento se divide automÃ¡ticamente en chunks
   - Se generan embeddings para cada chunk
   - Se almacena en Supabase con Ã­ndice vectorial
2. **Iniciar chat**: Haz preguntas sobre tu documento en lenguaje natural
3. **Recibir respuestas**: El sistema:
   - Genera un embedding de tu pregunta
   - Busca los chunks mÃ¡s relevantes usando similitud semÃ¡ntica
   - Construye un contexto con los fragmentos relevantes
   - Genera una respuesta usando GPT-4o basada en el contexto
4. **Ver fuentes**: Cada respuesta incluye los chunks relevantes con su nivel de similitud

### CategorÃ­as de Palabras Clave

- **Persona** (azul): Nombres de personas
- **OrganizaciÃ³n** (cian): Empresas, instituciones
- **Fecha** (verde): Fechas importantes
- **Cantidad** (rojo): Montos, nÃºmeros
- **UbicaciÃ³n** (naranja): Lugares, direcciones
- **Tema/Otro** (gris): Conceptos generales

## ğŸ—ï¸ Arquitectura

### Clean Architecture

El proyecto implementa una arquitectura limpia con las siguientes capas:

- **Dominio**: Entidades y puertos (interfaces)
- **AplicaciÃ³n**: Casos de uso y servicios de aplicaciÃ³n
- **Infraestructura**: Adaptadores para servicios externos
- **PresentaciÃ³n**: Componentes UI y API routes

### Flujo de Datos - AnÃ¡lisis de Keywords

1. Usuario sube PDF â†’ Componente UI
2. UI llama API `/api/analyze` â†’ API Route
3. API Route ejecuta `AnalyzePdfUseCase` â†’ Caso de Uso
4. Caso de Uso orquesta:
   - `PdfParseTextExtractor` â†’ Extrae texto
   - `OpenAIKeywordExtractor` â†’ Genera palabras clave
5. Resultado regresa a UI â†’ Muestra chips

### Flujo de Datos - RAG (Chat con Documentos)

#### 1. Almacenamiento de Documentos
```
Usuario sube PDF
    â†“
POST /api/documents/store
    â†“
StoreDocumentUseCase
    â†“
    â”œâ”€â†’ RecursiveTextChunker (divide en chunks)
    â”œâ”€â†’ OpenAIEmbeddingGenerator (genera embeddings)
    â””â”€â†’ SupabaseVectorStore (almacena en Supabase)
```

#### 2. Chat con RAG
```
Usuario hace pregunta
    â†“
POST /api/chat
    â†“
ChatWithDocsUseCase
    â†“
    â”œâ”€â†’ OpenAIEmbeddingGenerator (embedding de pregunta)
    â”œâ”€â†’ SupabaseVectorStore (bÃºsqueda semÃ¡ntica)
    â”œâ”€â†’ ContextAssembler (ensambla contexto)
    â”œâ”€â†’ ChatPromptBuilder (construye prompt)
    â””â”€â†’ OpenAIChatService (genera respuesta streaming)
         â†“
    Respuesta streaming + chunks relevantes
```

### Componentes Principales RAG

- **StoreDocumentUseCase** (`src/core/application/chat/use-cases/StoreDocumentUseCase.ts:69`)
  - Orquesta el proceso de almacenamiento de documentos
  - Divide, genera embeddings y almacena

- **ChatWithDocsUseCase** (`src/core/application/chat/use-cases/ChatWithDocsUseCase.ts:104`)
  - Orquesta el flujo RAG completo
  - BÃºsqueda semÃ¡ntica + generaciÃ³n de respuesta

- **RecursiveTextChunker** (`src/infrastructure/chunking/RecursiveTextChunker.ts`)
  - Divide documentos usando separadores jerÃ¡rquicos
  - Mantiene overlap entre chunks para contexto

- **OpenAIEmbeddingGenerator** (`src/infrastructure/embeddings/OpenAIEmbeddingGenerator.ts`)
  - Genera embeddings con OpenAI API
  - Soporta operaciones batch

- **SupabaseVectorStore** (`src/infrastructure/vector-store/SupabaseVectorStore.ts`)
  - Almacena y busca vectores usando pgvector
  - FunciÃ³n RPC `match_documents` para similitud coseno

## ğŸ”§ Scripts Disponibles

Con Yarn:
```bash
yarn dev         # Desarrollo
yarn build       # ConstrucciÃ³n para producciÃ³n
yarn start       # Servidor de producciÃ³n
yarn lint        # Linter ESLint
```

Con npm:
```bash
npm run dev      # Desarrollo
npm run build    # ConstrucciÃ³n para producciÃ³n
npm run start    # Servidor de producciÃ³n
npm run lint     # Linter ESLint
```

## ğŸš¨ Limitaciones

- **TamaÃ±o mÃ¡ximo**: 20MB por archivo (configurable)
- **Formato**: Solo archivos PDF
- **Persistencia Keywords**: Sin base de datos, solo en memoria
- **Persistencia RAG**: Requiere Supabase configurado
- **Costos**: Uso de OpenAI API (embeddings + chat)
- **Idioma**: Optimizado para espaÃ±ol, funciona con otros idiomas

## ğŸ”’ Seguridad

- API keys de OpenAI y Supabase solo en servidor
- ValidaciÃ³n de tipos de archivo
- LÃ­mites de tamaÃ±o de archivo
- Manejo de errores robusto
- Row Level Security (RLS) recomendado en Supabase para producciÃ³n
- SanitizaciÃ³n de inputs para prevenir inyecciÃ³n SQL

## ğŸ› SoluciÃ³n de Problemas

### Error: "OPENAI_API_KEY environment variable is required"
- Verifica que el archivo `.env.local` existe
- Confirma que la API key es vÃ¡lida
- Reinicia el servidor de desarrollo despuÃ©s de cambiar variables de entorno

### Error al cargar PDF
- Verifica que el archivo es un PDF vÃ¡lido
- Confirma que el tamaÃ±o no excede el lÃ­mite

### Palabras clave vacÃ­as
- Revisa que el PDF contiene texto extraÃ­ble
- Verifica la conectividad con OpenAI

### Error de conexiÃ³n con Supabase
- Verifica que `SUPABASE_URL` y `SUPABASE_ANON_KEY` estÃ¡n configuradas
- Confirma que la tabla `documents` existe en Supabase
- Verifica que la extensiÃ³n `pgvector` estÃ¡ habilitada
- Revisa que la funciÃ³n `match_documents` fue creada correctamente

### El chat no encuentra documentos relevantes
- Verifica que los documentos fueron almacenados correctamente
- Ajusta `RAG_SIMILARITY_THRESHOLD` (valores mÃ¡s bajos = menos estricto)
- Aumenta `RAG_MAX_RESULTS` para obtener mÃ¡s resultados
- Revisa los logs del servidor para ver los scores de similitud

### Respuestas lentas en el chat
- Considera usar un modelo mÃ¡s rÃ¡pido (ej. `gpt-4o-mini` en lugar de `gpt-4o`)
- Reduce `RAG_MAX_RESULTS` para buscar menos chunks
- Reduce `RAG_CHUNK_SIZE` para chunks mÃ¡s pequeÃ±os
- Optimiza el Ã­ndice vectorial en Supabase (aumenta `lists` en el Ã­ndice)

## ğŸ§  CÃ³mo Funciona RAG

### Â¿QuÃ© es RAG?

RAG (Retrieval-Augmented Generation) es una tÃ©cnica que combina:
1. **RecuperaciÃ³n**: BÃºsqueda de informaciÃ³n relevante en documentos
2. **GeneraciÃ³n**: CreaciÃ³n de respuestas usando LLMs con el contexto recuperado

### Proceso TÃ©cnico

#### 1. **IndexaciÃ³n de Documentos** (Cuando subes un PDF)
```
PDF â†’ ExtracciÃ³n de texto â†’ Chunking â†’ Embeddings â†’ Vector Store
```

- **Chunking**: El documento se divide en fragmentos de ~1000 caracteres con 200 de overlap
- **Embeddings**: Cada chunk se convierte en un vector de 1536 dimensiones usando `text-embedding-3-small`
- **Almacenamiento**: Los vectores se guardan en Supabase con un Ã­ndice IVFFLAT para bÃºsqueda eficiente

#### 2. **Consulta y Respuesta** (Cuando haces una pregunta)
```
Pregunta â†’ Embedding â†’ BÃºsqueda vectorial â†’ Top-K chunks â†’ Prompt + Contexto â†’ LLM â†’ Respuesta
```

- **Embedding de pregunta**: Tu pregunta se convierte en un vector usando el mismo modelo
- **Similitud coseno**: Se buscan los chunks mÃ¡s similares usando distancia vectorial
- **Threshold**: Solo se usan chunks con similitud > 0.7 (configurable)
- **Contexto**: Los top 5 chunks mÃ¡s relevantes se incluyen en el prompt
- **GeneraciÃ³n**: GPT-4o genera la respuesta basÃ¡ndose Ãºnicamente en el contexto proporcionado

### ConfiguraciÃ³n de ParÃ¡metros

| ParÃ¡metro | Variable de Entorno | Valor por Defecto | DescripciÃ³n |
|-----------|---------------------|-------------------|-------------|
| TamaÃ±o de chunk | `RAG_CHUNK_SIZE` | 1000 | Caracteres por fragmento |
| Overlap | `RAG_CHUNK_OVERLAP` | 200 | Caracteres compartidos entre chunks |
| Resultados | `RAG_MAX_RESULTS` | 5 | NÃºmero mÃ¡ximo de chunks a recuperar |
| Similitud | `RAG_SIMILARITY_THRESHOLD` | 0.7 | Umbral de similitud (0-1) |
| Modelo chat | `CHAT_MODEL` | gpt-4o | Modelo para generar respuestas |

### Ventajas de esta ImplementaciÃ³n

- âœ… **Respuestas precisas**: Basadas en tus documentos especÃ­ficos
- âœ… **Trazabilidad**: Cada respuesta incluye las fuentes utilizadas
- âœ… **Escalabilidad**: Supabase + pgvector maneja miles de documentos
- âœ… **Streaming**: Respuestas en tiempo real usando Vercel AI SDK
- âœ… **Clean Architecture**: FÃ¡cil de extender y mantener

## ğŸ“ Licencia

Este es un proyecto de demostraciÃ³n (POC) para fines educativos.
